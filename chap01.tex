\chapter{Problem Analysis \& Solution}

Present the solution.

%%-----------------------------------------------------------------------------------------
%%-----------------------------------------------------------------------------------------
\section{Seeing Mesh Difference as a Vector Field}

In our new visualizations, arrows will be used to represent the difference between two triangle meshes. Each arrow will be internally represented by a position and a direction vector. Together, they will form a discrete and bounded vector field. This is a very important abstraction because vector field visualization is a very rich area which finds applications in engineering, molecular modeling and computational fluid dynamics. Therefore, there exist many scientific papers studying this topic, such as \citet{Telea99}, \citet{Garcke00}, \citet{Du04} or \citet{Peng12}.

When visualizing a vector field, it is necessary to use clustering on the vectors to obtain a simplified representation, otherwise the visualization becomes too cluttered (see fig. \ref{fig:meshdiff_unclustered}). Clustering therefore determines to a large extent what the final visualization will look like.

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{./img/meshdiff-unclustered_arrows.PNG}
\caption{MeshDiff - Vertex distance visualized by unclustered arrows}
\label{fig:meshdiff_unclustered}
\end{figure}
%%-----------------------------------------------------------------------------------------
%% SECTION
%%-----------------------------------------------------------------------------------------
\section{Vector Field Clustering}

As clustering is a very subjective task (see fig. \ref{fig:clustering_subjectivity}), each of the above mentioned papers has their own way of dealing with it.

\begin{figure}[h]
\centering
\includegraphics[width=0.6\textwidth]{./img/clustering_subjectivity.png}
\caption{The subjectivity of clustering - are there two or four clusters in the image?}
\label{fig:clustering_subjectivity}
\end{figure}

%%-----------------------------------------------------------------------------------------
\subsection{Overview of Vector Field Clustering Methods}

\citet{Telea99} use hierarchical (bottom-up) clustering where neighboring clusters with the smallest clustering error are merged. Each cluster has a representative vector and when merging, a weighted average of the two vectors is computed and assigned to the newly formed cluster. The paper introduced elliptic iso-error contours to compute the clustering error. The method is primarily aimed at 2D rectilinear vector fields but can be also used in 3D.

\citet{Garcke00} use a continuous clustering method based on the physical model of \citet{CahnHilliard58} which is used to describe phase separation and coarsening in binary alloys. This model is applied to vector field data which results in a diffusion problem rather than a splitting and merging problem. Such an algorithm also presumes an either 2D or 3D rectilinear grid.

\citet{Du04} use iterative (top-down) clustering where Voronoi regions are created around the initial cluster centers and a distance function is applied to each of them. The set of cluster centers which has the lowest value of the distance function is selected as the final cluster centers set. This method works with 2D and 3D rectilinear vector fields.

\citet{Peng12} use hierarchical clustering similar to \citet{Telea99}, only they use the GPU to compute the clustering by encoding a certain static view of a mesh into a rasterized image. The computation is then done for this specific image. To obtain the clustering error, a very simple formula is employed:

\begin{equation} \label{eq:clustering_error}
\bm{e}(C_1,C_2) = k_d \cdot \frac{d_{C_1C_2}}{d_{max}} + k_v \cdot \frac{v_{C_1C_2}}{v_{max}} + k_\alpha \cdot \frac{\alpha_{C_1C_2}}{\alpha_{max}} + k_m \cdot \frac{m_{C_1C_2}}{m_{max}}
\end{equation}

where \(k_d + k_v + k_\alpha + k_m = 1\). The other components are the following:

\begin{itemize}
\item \(d_{C_1C_2}\) is the Euclidean distance between the positions of the representative vectors of the clusters. The maximum distance \(d_{max}\) is the length of a diagonal of the geometry's bounding box
\item \(v_{C_1C_2}\) is the difference between the lengths of the representative vectors. The maximum velocity \(v_{max}\) is the largest length in the whole data set.
\item \(\alpha_{C_1C_2}\) is angle between the representative vectors. The maximum angle \(\alpha_{max} = 180^\circ\)
\item \(m_{C_1C_2}\) is the sum of the mesh resolutions of the two clusters. \(m_{max}\) is the largest value of \(m\) in the whole data set.
\end{itemize}

The mesh resolution component also differentiates this approach from all others because it represents an approximation of the density of the mesh in a given local area. Including it in the error formula assigns higher error to dense clusters which results in a larger amount of clusters (higher precision) in dense areas of the mesh and a smaller amount of clusters (lower precision) in sparse areas of the mesh. This method is therefore aimed at non-rectilinear 3D meshes.
%%-----------------------------------------------------------------------------------------
\subsection{Our Clustering Method}

For our clustering purposes, it is convenient to choose one of the presented methods and modify it if necessary. This approach saves time and gives us a baseline which we can improve upon. When selecting a clustering method, it is necessary to find a balance between simplicity and the ease of use (parameter tuning). We will lean towards simplicity in order to quickly obtain our baseline and only later look for improvements once we have a better idea of the actual performance of the selected method in our conditions.

While the hierarchical clustering of \citet{Telea99} is very simple and seems like a good candidate, its error function does not take into account the varying density of our triangle meshes and is also more demanding to use in 3D. In order to calculate the error function, one needs to find the elliptic iso-error contour of a given vector. This leads to cube-root equations which would have to be computed for every pair of clustering candidates. The error function of \citet{Peng12} (see eq. \ref{eq:clustering_error}), on the other hand, is both sensitive to non-uniform meshes and computationally simpler and more scalable into higher dimensions.

Lastly, we will not use the GPU-based clustering computation from \citet{Peng12} because we need to be able to view the resulting visualizations easily from various angles in real time. The basic approach in \citet{Telea99} computes the clustering once for the whole vector field.

Our clustering method will use the hierarchical algorithm from \citet{Telea99} and the error function \ref{eq:clustering_error} from \citet{Peng12}. Merging of two clusters will be done by computing a weighted average of their representative vectors.
%%-----------------------------------------------------------------------------------------
\subsection{Algorithm}

Here is the pseudocode of the hierarchical clustering algorithm as presented in \citet{Telea99}:

\begin{algorithm}[H]
\caption{Clustering}
\begin{algorithmic}[1]

\Require ClusterSet s
\Statex
\For{all cells cell\textsubscript{i} \textbf{in} dataset}
	\State c = makeCluster(cell\textsubscript{i});
    \State set level of c to 0;
    \State add c to s;
\EndFor
\Statex
\For{all clusters c\textsubscript{i} in s}
	\For{all clusters c\textsubscript{j} neighbours of c\textsubscript{i}}
    	\State e = clusteringError(c\textsubscript{i}, c\textsubscript{j});
        \State insert pair (c\textsubscript{i}, c\textsubscript{j}) in increasing order of error e in a hash table;
        \State mark c\textsubscript{i} and c\textsubscript{j} as NOT\_CLUSTERED;
    \EndFor
\EndFor
\Statex
\State int i = 0;
\For{all pairs (c\textsubscript{i}, c\textsubscript{j}) in increasing order of error in the hash table}
	\If{both c\textsubscript{i} and c\textsubscript{j} are NOT\_CLUSTERED}
    	\State c = mergeClusters(c\textsubscript{i}, c\textsubscript{j});
        set level of c to l++;
        mark c\textsubscript{i} and c\textsubscript{j} as CLUSTERED;
        \For{all neighbors n\textsubscript{i} of c}
        	\State e = clusteringError(c, n\textsubscript{i});
            insert pair (c, n\textsubscript{i}) in order in hash table
        \EndFor
    \EndIf
\EndFor
\Statex
\Return c as root of tree
\end{algorithmic}
\end{algorithm}

There are two important functions in the algorithm, \texttt{clusteringError()} and \texttt{mergeClusters()}. \texttt{clusteringError()} uses formula \ref{eq:clustering_error} to compute the clustering error and therefore directly influence which clustering candidates will be merged first. \texttt{mergeClusters()} constructs the representative vector of the new cluster by computing a weighted average of the representative vectors of the merged clusters where the weight is the geometrical area of the clusters.
%%-----------------------------------------------------------------------------------------
\subsection{Improvements}

We also made one modification of the clustering algorithm which can be optionally turned on in the experimental application MeshDiff.

When we consider the surface of a triangle mesh with our vector field placed in the vertices of the mesh, there are two types of vectors - those pointing "inside" the mesh and those pointing "out" of the mesh. We found out that it might be useful to add one more condition to the clustering process and only allow those clusters to be merged whose representative arrows point in the same direction as outlined above. We say that such vectors have the same orientation.

The result of such a clustering is then a forest instead of a tree. This may result in certain clusterings not covering the whole mesh which does not necessarily lower the quality of the resulting visualization but should nevertheless be taken into account.
%%-----------------------------------------------------------------------------------------
%% SECTION
%%-----------------------------------------------------------------------------------------
\section{Proposed Visualizations}

Since our new visualizations are mostly arrow-based, we have chosen to visualize the following distance metrics:

\begin{itemize}
\item Vertex distance
\item Vertex distance projected into surface normal
\end{itemize}

Following are the descriptions of the new visualizations.

%%-----------------------------------------------------------------------------------------
\subsection{Arrows}

Once a clustering of the mesh difference vector field is obtained, representative vectors of all clusters are visualized using 3D arrows. For this purpose we have prepared a simple 3D model of an arrow which is copied to the scene at a specific position and a specific scale given by the representative vector and the cluster it belongs to.

The length of the representative vector encodes the difference metric now averaged across the whole cluster. This length also influences the scale of the 3D arrow. Because the values of the metric can be very close to zero and because their value range is not generally very large, we have decided set a certain minimum scale and maximum scale, which is adjustable by the user, and map the metric values (vector lengths) to this interval. In general, such an approach gives a more visually pleasing and clear results, especially when the interval is chosen to be large enough.

The scale of the 3D arrows also reflect the geometrical area of the clusters. The larger the clusters are, the thicker the arrows. Areas are again mapped to a user-defined interval for clearer result. Large clusters are usually important because they represent a trend in a given area and users should be able to see them more easily and also distinguish them from less important arrows.

Lastly, and most importantly, the direction of the representative vector is directly reflected in the direction of the 3D arrow. We have therefore managed to encode three-dimensional information into our visualization.

\subsubsection{Expected Performance}

Arrow visualizations combined with clustering are expected to perform well in answering questions about general trends in large parts of a mesh. They are also expected to perform considerably better than color-based visualizations when asking about the direction of the difference, which is particularly important in cases when the difference forms a very small angle with the surface of the mesh.
%%-----------------------------------------------------------------------------------------
\subsection{Cluster Color}

There are situations when the user requires clustering in order to see how larger parts of the meshes differ from one another but the richness of information offered by the arrow visualization is redundant. Also, one might simply want to see how the clustering itself behaves. For these use case we introduce two color visualizations of clusters - random and metric-based.

Both of these visualizations need to be aware of which mesh vertices belong to a given cluster. Then either a random color is assigned to all vertices in a given cluster or a color based on the length of the representative vector of the cluster is assigned. The former case is basically the original color visualization of a metric, only applied on clusters.

\subsubsection{Expected Performance}

Random cluster color is expected to be used for the purpose of configuring the clustering parameters as the size and the location of the clusters is clearly visible in this case.

Metric-based cluster color is expected to perform well in cases when we have found the most important differences using a more sophisticated visualization and want to present those using a visualization which is as clear as possible.
%%-----------------------------------------------------------------------------------------
\subsection{Thresholding}

For all types of metric-based visualizations, including the original color-based ones, we present thresholding. Each vertex or cluster which does not have a sufficiently high metric value assigned to it is excluded from the visualization. This method therefore works as a high-pass filter on the visualization.

\subsubsection{Expected Performance}

Thresholding is expected to enhance the effect of metric-based cluster color in that it is expected to perform very well when segmenting and emphasizing a previously discovered difference which is of importance to the user. It is also expected to help answer questions about the largest differences in the mesh.
%%-----------------------------------------------------------------------------------------
\subsection{Combined Visualizations}

The last visualization type presented in this thesis is the combination of color and arrow visualizations.

\subsubsection{Expected Performance}

Combined visualizations complement each other in areas when only one visualization is not sufficiently clear. Color visualizations are expected to highlight the dimension of the metric we are interested in the most, for example vertex distance magnitude, while arrow visualization are expected to carry the other dimensions like direction and cluster size. This method is expected to bring a balance between clarity and information richness.
%%-----------------------------------------------------------------------------------------
%% SECTION
%%-----------------------------------------------------------------------------------------
\section{Effect of Clustering Parameters on the Visualizations}

(include visualizer parameters in the descriptions above)

The function used for computing the clustering error (see eq. \ref{eq:clustering_error}) has four parameters:

\begin{itemize}
\item Direction weight
\item Position weight
\item Magnitude weight
\item Resolution weight
\end{itemize}

A specific configuration of these parameters can influence the outcome of the clustering process considerably. Setting the value of one of them higher than the others will cause the proportion of the corresponding part of the clustering error be higher than the others. This will make that part of the error more significant and cause cluster pair with low values in this area merge much easier than all the other cluster pairs.

%%-----------------------------------------------------------------------------------------
\subsection{Direction Weight}

High direction weight causes clusters whose representative vectors have similar directions merge easily regardless of their difference in position, magnitude and resolution. This results in uneven cluster sizes. It forms many small clusters in areas of high surface curvature and large clusters in flat areas. Therefore, it mostly captures the high-curvature changes of shape.
%%-----------------------------------------------------------------------------------------
\subsection{Position Weight}

Setting the position weight higher than others results in clusters of even size where each of them represents the overall difference in a certain area regardless of the variety of directions and magnitudes in that area.
%%-----------------------------------------------------------------------------------------
\subsection{Magnitude Weight}

Magnitude weight can play a significant role when using the metric-based cluster color visualization because its high value will highlight iso-magnitude contours. Such an approach can be useful when grouping and segmenting areas with a certain absolute value of the difference metric.
%%-----------------------------------------------------------------------------------------
\subsection{Resolution Weight}

High resolution weight prefers clustering in sparse areas of the mesh and will therefore increase the precision of the visualization in very dense areas. This effect partially complement direction weight because high-curvature areas of triangle meshes are usually more dense for the high-curvature to be captured well.